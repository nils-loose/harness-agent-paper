\documentclass[sigconf,review,anonymous]{acmart}

\usepackage{listings}
\usepackage[inkscapeopt={-D}]{svg}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{pifont}
\usepackage{rotating}
\usepackage{listings}
\usepackage{xcolor}

% YAML syntax highlighting - clean for academic papers
\lstdefinestyle{yaml}{
  basicstyle=\ttfamily\small,
  sensitive=false,
  comment=[l]{\#},
  commentstyle=\color{gray},
  showstringspaces=false,
  emphstyle=\bfseries,
  emph={get_method_code,description,method_signature,type,class_name,default},
  identifierstyle=,
  keywords={null, string},
}

% Java syntax highlighting
\definecolor{javared}{rgb}{0.6,0,0}          % for strings
\definecolor{javagreen}{rgb}{0.25,0.5,0.35}  % for comments
\definecolor{javapurple}{rgb}{0.5,0,0.35}    % for keywords
\definecolor{javadocblue}{rgb}{0.25,0.35,0.75} % for javadoc

\lstset{language=Java,
  basicstyle=\ttfamily\small,
  keywordstyle=\color{javapurple}\bfseries,
  stringstyle=\color{javared},
  commentstyle=\color{javagreen},
  morecomment=[s][\color{javadocblue}]{/**}{*/},
  showstringspaces=false,
  tabsize=2
}

% Define checkmark symbol
\newcommand{\cmark}{\ding{51}}

\setcopyright{acmlicensed}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{XXXXXXX.XXXXXXX}
\acmConference[Conference acronym 'XX]{Make sure to enter the correct
  conference title from your rights confirmation email}{June 03--05,
  2018}{Woodstock, NY}
\acmISBN{978-1-4503-XXXX-X/2018/06}
\acmSubmissionID{123}
% Define text styles for SVG rendering
\def\axtext{\footnotesize\sffamily}
\def\ticktext{\scriptsize\sffamily}


\begin{document}

\title{Multi-Agent Driven Fuzz-Harness Generation}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Ben Trovato}
\authornote{Both authors contributed equally to this research.}
\email{trovato@corporation.com}
\orcid{1234-5678-9012}
\author{G.K.M. Tobin}
\authornotemark[1]
\email{webmaster@marysville-ohio.com}
\affiliation{%
  \institution{Institute for Clarity in Documentation}
  \city{Dublin}
  \state{Ohio}
  \country{USA}
}

\author{Lars Th{\o}rv{\"a}ld}
\affiliation{%
  \institution{The Th{\o}rv{\"a}ld Group}
  \city{Hekla}
  \country{Iceland}}
\email{larst@affiliation.org}

\author{Valerie B\'eranger}
\affiliation{%
  \institution{Inria Paris-Rocquencourt}
  \city{Rocquencourt}
  \country{France}
}

\author{Aparna Patel}
\affiliation{%
 \institution{Rajiv Gandhi University}
 \city{Doimukh}
 \state{Arunachal Pradesh}
 \country{India}}

\author{Huifen Chan}
\affiliation{%
  \institution{Tsinghua University}
  \city{Haidian Qu}
  \state{Beijing Shi}
  \country{China}}

\author{Charles Palmer}
\affiliation{%
  \institution{Palmer Research Laboratories}
  \city{San Antonio}
  \state{Texas}
  \country{USA}}
\email{cpalmer@prl.com}

\author{John Smith}
\affiliation{%
  \institution{The Th{\o}rv{\"a}ld Group}
  \city{Hekla}
  \country{Iceland}}
\email{jsmith@affiliation.org}

\author{Julius P. Kumquat}
\affiliation{%
  \institution{The Kumquat Consortium}
  \city{New York}
  \country{USA}}
\email{jpkumquat@consortium.net}

\renewcommand{\shortauthors}{Trovato et al.}


\begin{abstract}
TODO: Klaus generate Abstract
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10010147.10010257</concept_id>
       <concept_desc>Computing methodologies~Machine learning</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10011007</concept_id>
       <concept_desc>Software and its engineering</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10011007.10011006</concept_id>
       <concept_desc>Software and its engineering~Software notations and tools</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10002978.10003022</concept_id>
       <concept_desc>Security and privacy~Software and application security</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Machine learning}
\ccsdesc[500]{Software and its engineering}
\ccsdesc[500]{Software and its engineering~Software notations and tools}
\ccsdesc[500]{Security and privacy~Software and application security}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{fuzzing, fuzz harness generation, large language models, multi-agent systems, automated software testing, program analysis, feedback-driven refinement, Java ecosystem, coverage-guided fuzzing, software security}


\maketitle

\section{Introduction}

Coverage-guided fuzzing has emerged as the dominant approach for discovering robustness vulnerabilities in systems software, libraries, and frameworks~\cite{CITE}. Yet its effectiveness on \emph{library code} fundamentally depends on the availability of high-quality \emph{fuzz harnesses}, i.e., specialized programs that bridge unstructured fuzzer inputs to structured API invocations. Manual harness construction remains a formidable barrier to scalable library fuzzing: developers must reverse-engineer API preconditions, synthesize realistic call sequences, and navigate complex build environments with transitive dependencies and environmental constraints. In ecosystems like Java, where libraries often require intricate Maven dependency graphs, reflection-based initialization, and runtime configuration, harness authoring has become the principal bottleneck limiting fuzzing coverage.

The research community has pursued three complementary strategies to automate harness generation. \emph{Usage-based approaches} mine API call patterns from existing client code or test suites, repurposing observed interactions as fuzzing drivers~\cite{DBLP:conf/sigsoft/BabicBCIKKLSW19:FUDGE, DBLP:conf/uss/IspoglouAMP20:FuzzGen, DBLP:conf/sp/JeongJYMKJKSH23:UTopia, DBLP:conf/icse/ZhangZLWLZJ23:Daisy, DBLP:journals/pacmse/WuNH25:WildSync}. While these methods capture realistic usage patterns, they inherently require rich consumer corpora, a condition rarely satisfied for niche libraries, legacy codebases, or newly released APIs. \emph{Structure- and API-based approaches} circumvent this limitation by deriving harnesses directly from type signatures, interface specifications, or dataflow graphs~\cite{DBLP:conf/icse/ZhangLMZ021:IntelliGen, DBLP:conf/icse/GreenA22:GraphFuzz, DBLP:conf/ccs/ChenXLWC23:Hopper, DBLP:conf/issta/XiongDCQWSZ24:Atlas, DBLP:journals/pacmse/ToffaliniBTP25:LibErator, DBLP:conf/icse/ShermanN25:OGHarn, DBLP:conf/ndss/0007ZLSZLQ25:NEXZZER}. However, these techniques struggle with non-obvious API contracts and often depend on domain-specific heuristics or human-in-the-loop guidance to resolve ambiguities. \emph{Feedback-driven approaches} close the loop through iterative refinement, using compilation errors, runtime exceptions, or coverage signals to guide harness evolution~\cite{DBLP:conf/uss/ZhangLZZZZXLL0H23:Rubick, DBLP:journals/pacmse/ToffaliniBTP25:LibErator, DBLP:conf/icse/ShermanN25:OGHarn, DBLP:conf/ndss/0007ZLSZLQ25:NEXZZER}. Despite their promise, existing feedback systems typically focus on narrow domains or lack robust mechanisms to automatically resolve build failures and environmental misconfigurations.

Large Language Models (LLMs) offer a path forward by combining code synthesis capabilities with learned knowledge of API usage patterns and debugging strategies. Early work has explored LLM-driven harness generation, revealing both opportunities and fundamental challenges: semantic drift under iterative refinement, brittleness to build system variations, and difficulties grounding generation in concrete coverage objectives~\cite{DBLP:conf/issta/ZhangZBLMXLSL24:HowEffectiveAreThey, DBLP:conf/sigsoft/Jiang0MCZSWFWLZ24:WhenFuzzingMeetsLLMs}. Recent systems have demonstrated progress through coverage-guided prompt evolution~\cite{DBLP:conf/ccs/LyuXCC24:PromptFuzz}, knowledge graph augmentation~\cite{DBLP:conf/icse/XuMZZCHLW25:CKGFuzzer}, and multi-agent coordination~\cite{DBLP:journals/corr/abs-2507-18289:Scheduzz}. However, a critical gap remains: no existing approach provides a fully automated, end-to-end pipeline that handles environment preparation, synthesis, compilation repair, and coverage-driven optimization without manual intervention.

We address this gap through a multi-agent system designed specifically for Java library fuzzing. Java serves as an ideal target for several reasons. First, its ecosystem comprises millions of Maven-hosted libraries that form the backbone of enterprise software infrastructure~\cite{CITE}, creating both high-impact fuzzing opportunities and a representative testbed for automation techniques. Second, Java's characteristics, i.e., deep dependency graphs, reflection-heavy APIs, and complex runtime requirements, stress-test the limits of automated harness generation, forcing confrontation with the very challenges that have hindered prior work. Third, solutions developed for Java's managed runtime and rich metadata naturally extend to similar ecosystems (Kotlin, Scala, .NET), amplifying broader impact.

We present a multi-agent architecture that orchestrates specialized LLM-based reasoning agents through a structured feedback loop. Our system decomposes harness generation into distinct phases (i.e., environment preparation, exploratory research, synthesis, validation, and refinement) each handled by dedicated agents equipped with domain-specific tools. Central to our approach is a tool-augmented reasoning framework that enables agents to query code structure, documentation, and implementation details on demand rather than relying on pre-computed summaries. Agents leverage Class Hierarchy Analysis to construct call graphs, retrieve API documentation from Javadoc archives, and examine source implementations—all through conversational exploration that adapts to the specific needs of each target library. Synthesis proceeds through iterative refinement guided by compilation diagnostics and coverage feedback, with separate agents specialized for generation (creative API exploration) and debugging (systematic error diagnosis). The result is a closed-loop workflow that autonomously produces compilable, coverage-optimized harnesses without requiring consumer code or manual intervention.

Our contributions advance the state of automated harness generation:
\begin{itemize}
    \item \textbf{A principled multi-agent architecture for end-to-end harness synthesis.} We introduce a workflow that decomposes harness generation into specialized reasoning tasks coordinated through adaptive feedback loops, eliminating reliance on consumer code, hand-crafted heuristics, or manual triage of build failures.

    \item \textbf{Model Context Protocol for tool-augmented code exploration.} We present an extensible framework enabling LLM agents to perform lazy, conversational queries against code analysis backends, thus transforming static analysis from a rigid preprocessing step into an adaptive reasoning resource.

    \item \textbf{Coverage-guided refinement} We demonstrate systematic improvement of harness quality through critic-agent collaboration, multi-criteria convergence detection, and cycle-aware exploration strategies that prevent semantic drift while maximizing achieved coverage.

    \item \textbf{Empirical validation on real-world Java libraries.} We evaluate our approach against established baselines including Jazzer's AutoFuzz and OSS-Fuzz-Gen, TODO: wir sind besser
\end{itemize}


\section{Preliminaries}

This section establishes the technical foundation for our approach, introducing coverage-guided fuzzing for managed runtimes, the role of large language models in code synthesis, and relevant baseline systems.

\subsection{Coverage-Guided Fuzzing and Harness Design}
\label{sec:prelim:fuzzing}

Coverage-guided fuzzing operates by repeatedly executing a program with generated inputs while monitoring code coverage feedback. Each execution provides feedback, typically in the form of newly covered branches or basic blocks, that guides subsequent input mutations toward unexplored program regions. This feedback loop enables fuzzers to systematically navigate complex input spaces and discover deep bugs that evade random testing.

Applying coverage-guided fuzzing to library code introduces a fundamental challenge: libraries expose APIs rather than standalone executables, requiring a \emph{fuzz harness} to mediate between the fuzzer and the target. A harness transforms unstructured byte streams from the fuzzer into valid API invocations by: (1)~parsing fuzz input into structured data types, (2)~constructing necessary object state and satisfying initialization preconditions, (3)~invoking target methods with derived arguments, and (4)~handling or observing exceptions and abnormal termination. The quality of this translation directly determines fuzzing effectiveness: shallow harnesses that merely parse inputs yield limited coverage, while well-designed harnesses that exercise complex API interactions expose deeper program logic and uncover latent bugs.

\subsection{Jazzer: Coverage-Guided Fuzzing for the JVM}
\label{sec:prelim:jazzer}

Jazzer~\cite{CITE:Jazzer} brings coverage-guided fuzzing to the Java Virtual Machine through a hybrid architecture combining native code instrumentation with JVM bytecode manipulation. The fuzzer executes as a native process that invokes Java methods via JNI, while a Java agent instruments target bytecode at class-load time to collect coverage feedback. This design enables efficient in-process fuzzing with fine-grained branch coverage, comparable to AFL and libFuzzer for native code.

Jazzer harnesses implement a standard interface that provides methods for consuming integers, strings, booleans, and other primitive types. Harness authors use this interface to construct valid inputs and orchestrate API calls. While manual harness creation remains common practice, Jazzer includes an AutoFuzz mode that leverages Java reflection to automatically generate harnesses. AutoFuzz discovers accessible constructors and methods, recursively building required objects and mapping fuzzer bytes to parameter types. 


\subsection{Large Language Models for Code Synthesis}
\label{sec:prelim:llm}

Large Language Models (LLMs) are transformer-based neural architectures trained on massive corpora of source code and natural language to predict and generate token sequences. Through next-token prediction over billions of parameters, LLMs internalize syntactic patterns, API usage idioms, and semantic relationships between code elements. When conditioned on appropriate context—such as function signatures, documentation, or partial implementations—LLMs can synthesize plausible code completions, generate test cases, or repair buggy programs~\cite{CITE:Codex,CITE:AlphaCode}.

Recent work has demonstrated that LLMs can be organized into multi-agent systems where distinct instances specialize in complementary subtasks~\cite{CITE:MultiAgentCode}. Rather than relying on a single monolithic prompt, multi-agent architectures decompose complex objectives into stages handled by specialized agents that communicate through structured message passing or shared state. For code generation tasks, this decomposition enables separation of concerns: one agent explores API documentation and infers usage patterns, another synthesizes implementations, while a third diagnoses compilation errors and proposes fixes. This division of labor mirrors human collaborative workflows and has been shown to improve both generation quality and success rates on challenging benchmarks~\cite{CITE:AgentBench}.

\subsection{Tool-Augmented LLM Reasoning}
\label{sec:prelim:tools}

While LLMs demonstrate impressive code understanding from pre-training, their knowledge is static and limited to patterns observed in training data. \emph{Tool-augmented reasoning} addresses this limitation by equipping LLMs with external capabilities they can invoke during generation~\cite{DBLP:conf/nips/SchickDSHWSCSW23:Toolformer,CITE:ToolLLM}. For code synthesis tasks, relevant tools include compilers (to validate syntax), test executors (to verify functional correctness), static analyzers (to extract API signatures), and documentation retrievers (to ground generation in current libraries).

The ReAct (Reasoning and Acting) paradigm~\cite{DBLP:conf/iclr/YaoZYDN023:ReAct} formalizes tool use as an interleaved process: the model alternates between reasoning steps (generating natural language explanations of its strategy) and action steps (invoking tools and observing outputs). This loop continues until the model determines it has sufficient information to complete the task. ReAct-style agents have demonstrated substantial improvements over direct prompting on tasks requiring information retrieval, calculation, or interaction with external systems.

\subsection{Baseline: OSS-Fuzz-Gen}
\label{sec:prelim:ossfuzzgen}

OSS-Fuzz-Gen~\cite{CITE:OSSFuzzGen} represents the current state-of-the-art in LLM-driven harness generation. It combines lightweight static analysis with iterative LLM prompting to synthesize harnesses for libraries integrated into Google's OSS-Fuzz continuous fuzzing service. The system operates in three phases: (1)~static analysis extracts function signatures and type information, (2)~an LLM generates candidate harnesses conditioned on templates encoding language-specific patterns (e.g., Java exception handling, C++ RAII), and (3)~compilation and short fuzzing trials filter invalid or low-coverage candidates.
OSS-Fuzz-Gen's Java extension provides language-specific prompt templates that guide harness structure for Java libraries. 



\input{sections/main-chapter.tex}
\input{sections/evaluation.tex}




\section{Related Work}
\label{sec:related-work}

This section reviews existing approaches to automated harness generation, positioning our work within the broader research landscape through a comprehensive survey of classical and modern techniques.

\subsection{Classical Approaches to Harness Generation}
\label{subsec:classical-harness-generation}



Different traditions of program analysis have shaped how fuzzing harnesses are constructed. A first line of work can be described as \textbf{(1) usage-based generation}, where valid API calls are mined from existing consumer code or unit tests and then repurposed to build drivers. This strategy captures realistic interaction patterns between libraries and clients, as demonstrated by systems that slice client code into reusable API snippets~\cite{DBLP:conf/sigsoft/BabicBCIKKLSW19:FUDGE}, construct harness stubs from API dependence graphs extracted from consumer projects~\cite{DBLP:conf/uss/IspoglouAMP20:FuzzGen}, inject fuzzed inputs into test cases while preserving their order~\cite{DBLP:conf/sp/JeongJYMKJKSH23:UTopia}, or aggregate traces and snippets from package repositories~\cite{DBLP:journals/pacmse/WuNH25:WildSync, DBLP:conf/icse/ZhangZLWLZJ23:Daisy}.

In contrast, \textbf{(2) structure- or API-based generation} avoids reliance on external code and derives harnesses directly from type signatures, header files, or interface specifications. Approaches in this category focus on risky functions such as dereferences~\cite{DBLP:conf/icse:ZhangLMZ021:IntelliGen}, build dataflow graphs to capture API interactions~\cite{DBLP:conf/icse/GreenA22:GraphFuzz}, adapt this principle to specific domains such as OEM Android components and JNI bindings~\cite{DBLP:conf/ccs/ChenXLWC23:Hopper, DBLP:conf/uss/IspoglouAMP20:FuzzGen, DBLP:conf/issta/XiongDCQWSZ24:Atlas}, or introduce intermediate representations, API-flow clustering, and constraint learning to enable application to large-scale or closed-source libraries~\cite{DBLP:journals/pacmse/ToffaliniBTP25:LibErator, DBLP:conf/icse/ShermanN25:OGHarn, DBLP:conf/ndss/0007ZLSZLQ25:NEXZZER}.

Finally, there is \textbf{(3) evolutionary or feedback-driven generation}, where harnesses are refined iteratively based on runtime signals such as coverage or oracle checks. This approach uses automaton learning on API usage patterns~\cite{DBLP:conf/uss/ZhangLZZZZXLL0H23:Rubick}, ranks and selects candidate harnesses after short fuzzing trials~\cite{DBLP:journals/pacmse/ToffaliniBTP25:LibErator}, filters out misuses through relation learning~\cite{DBLP:conf/ndss/0007ZLSZLQ25:NEXZZER}, or validates candidates using compile-time and runtime oracles~\cite{DBLP:conf/icse/ShermanN25:OGHarn}. These systems demonstrate how feedback loops can drive continuous improvement, in contrast to static one-shot generation.

\subsection{LLM-based Approaches}
\label{subsec:llm-approaches}


With the availability of large language models, harness generation has also been explored from a learning perspective. One stream of work takes the form of \textbf{(1) feasibility studies}, which probe the capabilities and limitations of LLMs in fuzzing. These studies evaluate different prompting strategies across benchmarks~\cite{DBLP:conf/issta/ZhangZBLMXLSL24:HowEffectiveAreThey} and discuss fundamental obstacles such as semantic drift and the absence of reliable oracles~\cite{DBLP:conf/sigsoft/Jiang0MCZSWFWLZ24:WhenFuzzingMeetsLLMs}.

Beyond these exploratory efforts, a growing body of research investigates \textbf{(2) automatic harness synthesis with LLMs}. Systems in this category introduce coverage-guided prompt mutation for iterative refinement~\cite{DBLP:conf/ccs/LyuXCC24:PromptFuzz}, augment LLM reasoning with knowledge graphs of API relations~\cite{DBLP:conf/icse/XuMZZCHLW25:CKGFuzzer}, address binary-only interfaces with agent-based synthesis~\cite{DBLP:journals/corr/abs-2507-15058:LibLMFuzz}, target unsafe Rust APIs~\cite{DBLP:journals/corr/abs-2506-15648:deepSURF}, integrate CVE metadata to guide call-chain harnesses~\cite{DBLP:journals/corr/abs-2505-03425:HGFuzzer}, or employ constraint dependency graphs for Python libraries~\cite{DBLP:journals/cybersec/LiuLZZLL25:LLM4TDG}.

A particularly promising movement is \textbf{(3) hybrid and multi-agent architectures}, where LLMs are embedded into broader analytic ecosystems. Approaches in this category orchestrate several agents around a knowledge graph~\cite{DBLP:conf/icse/XuMZZCHLW25:CKGFuzzer}, combine LLM-based repair with solver-driven scheduling~\cite{DBLP:journals/corr/abs-2507-18289:Scheduzz}, or integrate LLM reasoning into static analysis pipelines built on CodeQL and Tree-Sitter~\cite{DBLP:journals/corr/abs-2505-03425:HGFuzzer}. These works illustrate the potential of combining generative capabilities with structured analysis and feedback mechanisms.


\section{Conclusion and Outlook}
TODO


%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{main}


\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.