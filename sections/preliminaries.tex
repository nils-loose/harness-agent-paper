
\section{Preliminaries}

\paragraph{Harness Design for Coverage-Guided Fuzzing}
Coverage-guided fuzzers generate test inputs by mutating input sequences based on code coverage feedback. When fuzzing library APIs, a \emph{fuzz harness} serves as the entry point that translates fuzzer-generated bytes into valid API invocations. An effective harness must parse input bytes into appropriate data types, construct required object states to satisfy API preconditions, invoke target methods with derived arguments, and handle exceptions appropriately to distinguish expected error conditions from genuine bugs. The harness design directly impacts fuzzing effectiveness. A harness that causes expected exceptions before invoking the target method wastes fuzzing cycles without exploring the targeted library logic. Conversely, a harness that exercises diverse API paths and satisfies complex preconditions enables the fuzzer to reach deeper code and discover latent bugs.

\paragraph{Tool-Augmented Reasoning}
Tool-augmented reasoning equips LLMs with external capabilities they can invoke during generation~\cite{DBLP:conf/nips/SchickDSHWSCSW23:Toolformer,CITE:ToolLLM}. The ReAct (Reasoning and Acting) paradigm~\cite{DBLP:conf/iclr:YaoZYDN023:ReAct} formalizes tool use as an interleaved process where the model alternates between reasoning steps that generate natural language explanations of its strategy and action steps that invoke tools and observe outputs. For code generation, tools typically include documentation search, source code retrieval, compilation, and test execution. Rather than providing all information upfront in a single prompt, ReAct agents query information on demand as their reasoning progresses.

\paragraph{Multi-Agent LLM Architectures}
Recent work has demonstrated that LLMs can be organized into multi-agent systems where distinct instances specialize in complementary subtasks~\cite{CITE:MultiAgentCode}. Rather than relying on a single monolithic prompt, multi-agent architectures decompose complex objectives into stages handled by specialized agents that communicate through structured message passing or a shared state. For code generation tasks, this decomposition enables separation of concerns where one agent explores API documentation, another synthesizes implementations, and a third diagnoses compilation errors. This division of labor has been shown to improve both generation quality and success rates on challenging benchmarks~\cite{CITE:AgentBench}.

\paragraph{Model Context Protocol}
The Model Context Protocol~\cite{mcp} standardizes how LLM agents access external resources through structured tool interfaces. MCP defines a client-server architecture where agents act as clients that invoke tools exposed by servers managing data sources. Each tool accepts structured parameters and returns formatted responses optimized for LLM consumption. For code analysis tasks, an MCP server might expose tools such as retrieving method source code or searching API documentation. MCP enables query-driven information retrieval where agents request precisely scoped information as needed. 
