
\section{Preliminaries}

This section establishes the technical foundation for our approach, introducing harness design challenges, fuzzing infrastructure for the JVM, and agent-based LLM architectures.

\subsection{Harness Design for Coverage-Guided Fuzzing}
\label{sec:prelim:fuzzing}

Applying coverage-guided fuzzing to library code introduces a fundamental challenge: libraries expose APIs rather than standalone executables, requiring a \emph{fuzz harness} to mediate between the fuzzer and the target. A harness transforms unstructured byte streams from the fuzzer into valid API invocations by: (1)~parsing fuzz input into structured data types, (2)~constructing necessary object state and satisfying initialization preconditions, (3)~invoking target methods with derived arguments, and (4)~handling or observing exceptions and abnormal termination. The quality of this translation directly determines fuzzing effectiveness: shallow harnesses that merely parse inputs yield limited coverage, while well-designed harnesses that exercise complex API interactions expose deeper program logic and uncover latent bugs.

\subsection{Jazzer and Baseline Systems}
\label{sec:prelim:jazzer}

Jazzer~\cite{CITE:Jazzer} is a coverage-guided fuzzer for the Java Virtual Machine that enables in-process fuzzing with fine-grained branch coverage feedback. Jazzer harnesses implement a standard interface for consuming fuzzer-generated primitives (integers, strings, booleans) to construct valid inputs and orchestrate API calls. While manual harness creation remains common practice, Jazzer includes an AutoFuzz mode that leverages Java reflection to automatically generate harnesses by discovering accessible constructors and methods, recursively building required objects through structure-aware instantiation.

OSS-Fuzz~\cite{CITE:OSSFuzz} is Google's continuous fuzzing service for open source software, launched in 2016 to provide free, large-scale fuzzing infrastructure. As of 2025, OSS-Fuzz has helped identify over 13,000 vulnerabilities across 1,000+ projects. All target methods in our evaluation have existing manually-written harnesses in OSS-Fuzz, providing a strong baseline for comparison.

\subsection{Multi-Agent LLM Architectures}
\label{sec:prelim:llm}

Recent work has demonstrated that LLMs can be organized into multi-agent systems where distinct instances specialize in complementary subtasks~\cite{CITE:MultiAgentCode}. Rather than relying on a single monolithic prompt, multi-agent architectures decompose complex objectives into stages handled by specialized agents that communicate through structured message passing or shared state. For code generation tasks, this decomposition enables separation of concerns: one agent explores API documentation and infers usage patterns, another synthesizes implementations, while a third diagnoses compilation errors and proposes fixes. This division of labor mirrors human collaborative workflows and has been shown to improve both generation quality and success rates on challenging benchmarks~\cite{CITE:AgentBench}.

\subsection{Tool-Augmented Reasoning}
\label{sec:prelim:tools}

Tool-augmented reasoning equips LLMs with external capabilities they can invoke during generation~\cite{DBLP:conf/nips/SchickDSHWSCSW23:Toolformer,CITE:ToolLLM}. The ReAct (Reasoning and Acting) paradigm~\cite{DBLP:conf/iclr/YaoZYDSN023:ReAct} formalizes tool use as an interleaved process: the model alternates between reasoning steps (generating natural language explanations of its strategy) and action steps (invoking tools and observing outputs). This loop continues until the model determines it has sufficient information to complete the task. ReAct-style agents have demonstrated substantial improvements over direct prompting on tasks requiring information retrieval, calculation, or interaction with external systems.
