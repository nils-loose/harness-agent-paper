\section{Related Work}
\label{sec:related-work}

\paragraph{Classical Harness Generation}
Different traditions of program analysis have shaped how fuzzing harnesses are constructed. \textbf{Usage-based generation} mines valid API calls from existing consumer code or unit tests, as demonstrated by systems that slice client code into reusable API snippets~\cite{DBLP:conf/sigsoft/BabicBCIKKLSW19:FUDGE}, construct harness stubs from API dependence graphs~\cite{DBLP:conf/uss/IspoglouAMP20:FuzzGen}, or inject fuzzed inputs into test cases~\cite{DBLP:conf/sp/JeongJYMKJKSH23:UTopia}. While this captures realistic interaction patterns, it remains dependent on the availability of suitable consumer code. In contrast, \textbf{structure-based generation} derives harnesses directly from type signatures and interface specifications, building dataflow graphs to capture API interactions~\cite{DBLP:conf/icse/GreenA22:GraphFuzz} or introducing intermediate representations for large-scale libraries~\cite{DBLP:journals/pacmse:ToffaliniBTP25:LibErator, DBLP:conf/icse/ShermanN25:OGHarn}. These approaches offer broader applicability but often lack iterative refinement, leaving adaptation to new targets largely manual. \textbf{Feedback-driven generation} refines harnesses iteratively using runtime signals, employing automaton learning on API usage patterns~\cite{DBLP:conf/uss/ZhangLZZZZXLL0H23:Rubick} or validating candidates using compile-time and runtime oracles~\cite{DBLP:conf/icse:ShermanN25:OGHarn}. While promising, such systems frequently rely on domain-specific heuristics or fixed coverage thresholds for termination decisions.

\paragraph{LLM-based Harness Synthesis}
% TODO: Add OSS-Fuzz citation - Google's continuous fuzzing service with manually-written harnesses as baseline
With the availability of large language models, harness generation has been explored from a learning perspective. Early feasibility studies evaluate prompting strategies~\cite{DBLP:conf/issta/ZhangZBLMXLSL24:HowEffectiveAreThey} and identify obstacles such as semantic drift~\cite{DBLP:conf/sigsoft/Jiang0MCZSWFWLZ24:WhenFuzzingMeetsLLMs}. Recent systems demonstrate automatic synthesis through coverage-guided prompt mutation for iterative refinement~\cite{DBLP:conf/ccs/LyuXCC24:PromptFuzz}, which mutates prompts based on coverage feedback but lacks semantic interpretation of coverage gaps. CKGFuzzer~\cite{DBLP:conf/icse/XuMZZCHLW25:CKGFuzzer} augments LLM reasoning with knowledge graphs of API relations, preprocessing entire API surfaces into static graphs before generation. Other approaches integrate LLM reasoning into static analysis pipelines~\cite{DBLP:journals/corr/abs-2505-03425:HGFuzzer} or combine LLM-based repair with solver-driven scheduling~\cite{DBLP:journals/corr/abs-2507-18289:Scheduzz}. However, most approaches either preprocess all information upfront (risking context saturation and prioritizing breadth over target-specific depth) or lack mechanisms for agents to iteratively query documentation and source code as reasoning progresses. Our work provides agents with query-based access to documentation, source code, and callgraph information through the Model Context Protocol~\cite{mcp}, enabling on-demand retrieval as reasoning needs emerge. While practical tools like OSS-Fuzz-Gen~\cite{oss-fuzz-gen} employ comparable multi-agent workflows with generic source access and fixed iteration counts, we provide specialized static analysis (callgraph construction, method-targeted coverage) and adaptive orchestration where coverage analysis agents determine iteration budgets dynamically. We extend feedback-driven refinement~\cite{DBLP:conf/ccs/LyuXCC24:PromptFuzz, DBLP:conf/uss/ZhangLZZZZXLL0H23:Rubick} by delegating termination decisions to agents that interpret coverage gaps, rather than applying fixed thresholds or heuristics.
% TODO: Add Jazzer/AutoFuzz citation - reflection-based automatic harness generation for Java
