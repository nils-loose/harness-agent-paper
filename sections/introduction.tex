\section{Introduction}

Coverage-guided fuzzing has become a fundamental technique for discovering bugs and vulnerabilities in software systems. When applied to library code, its effectiveness depends on the availability of high-quality fuzz harnesses. A harness serves as an adapter between the fuzzer and the target library, transforming unstructured byte sequences into valid API invocations that exercise library logic. Manual harness creation remains a significant obstacle to widespread fuzzing adoption. Developers must understand API contracts, construct valid object states, synthesize realistic call sequences, and implement appropriate exception handling. This time-intensive process limits the number of library APIs that receive comprehensive fuzzing coverage. This challenge is particularly acute for Java libraries, which remain underrepresented in continuous fuzzing infrastructure and research despite the widespread deployment of Java applications in production systems. 

Existing automated harness generation approaches face complementary limitations. Usage-based methods mine API interaction patterns from consumer code~\cite{DBLP:conf/sigsoft/BabicBCIKKLSW19:FUDGE,DBLP:conf/sp/JeongJYMKJKSH23:UTopia} but require access to substantial client corpora that may be unavailable for specialized or newly released libraries. Structure-based approaches derive harnesses from type signatures and interface specifications~\cite{DBLP:conf/icse/GreenA22:GraphFuzz,DBLP:conf/icse/ShermanN25:OGHarn} but struggle with implicit preconditions and often rely on domain-specific heuristics that limit generalizability. Feedback-driven methods employ iterative refinement based on runtime signals~\cite{DBLP:conf/uss/ZhangLZZZZXLL0H23:Rubick} but typically apply fixed termination thresholds without semantic interpretation of coverage gaps. Recent LLM-based systems demonstrate progress through coverage-guided prompt evolution~\cite{DBLP:conf/ccs/LyuXCC24:PromptFuzz} and knowledge graph augmentation~\cite{DBLP:conf/icse/XuMZZCHLW25:CKGFuzzer}. However, these approaches lack mechanisms for iterative, query-driven exploration of codebases during generation. 

Large language models present new opportunities for automated harness generation by combining code synthesis capabilities with domain specific knowledge. However, directly applying LLMs to this task introduces distinct challenges. Preprocessing entire API surfaces exhausts available context windows, particularly for large library ecosystems with extensive dependency graphs. One-shot generation fails on complex libraries requiring multi-step initialization sequences or non-obvious preconditions. Coverage-based refinement risks semantic drift when agents lack mechanisms to interpret what coverage gaps represent and whether they indicate addressable deficiencies or fundamental limitations. These observations suggest that effective harness generation requires an approach that integrates LLM reasoning with targeted program analysis, retrieves information on demand rather than preprocessing entire codebases, and interprets coverage feedback semantically rather than applying fixed numerical thresholds.

We address these challenges through a multi-agent architecture that decomposes harness generation into specialized reasoning tasks. Five ReAct agents handle distinct phases of the workflow. The research agent explores API documentation and source code to understand target method semantics. The synthesis agent transforms this understanding into initial harness implementations. The compilation agent diagnoses and repairs build errors through iterative refinement. The coverage analysis agent interprets coverage gaps by examining uncovered source code to determine whether further refinement is worthwhile. The refinement agent modifies harnesses to address identified coverage deficiencies. Rather than preprocessing entire API surfaces into static knowledge graphs, agents query information on demand through the Model Context Protocol. This query-driven approach retrieves documentation for specific methods, source code for particular classes, and callgraph fragments rooted at selected invocations. The design maintains focused context while exploring large dependency graphs, enabling autonomous handling of complex build configurations and iterative compilation repair.

Two technical mechanisms enable effective coverage-guided refinement. First, we introduce method-targeted coverage instrumentation that activates JaCoCo tracking only during target method execution. Standard instrumentation measures all executed code, creating misaligned incentives where harnesses invoke unrelated utility methods to inflate coverage metrics. Our approach ensures that coverage measurements reflect target behavior rather than incidental framework initialization. Second, we implement agent-guided termination that interprets coverage gaps through source code analysis. The coverage analysis agent examines uncovered methods to distinguish addressable deficiencies such as missing input variants or unexplored API paths from fundamental limitations such as unreachable defensive code or external I/O dependencies. This interpretation enables the system to stop refinement when it yields diminishing returns while continuing when concrete improvement strategies exist.

We evaluate our approach on seven target methods from six widely deployed Java libraries spanning parsers, JSON processors, and core utilities. The selected libraries total over 115,000 Maven dependents and represent real-world fuzzing targets. All targets have existing manually written harnesses in OSS-Fuzz, providing strong baselines for comparison. Our generated harnesses achieve a median improvement of 26\% in method-targeted coverage over OSS-Fuzz baselines and outperform both OSS-Fuzz and Jazzer AutoFuzz by 6\% and 5\% respectively under full package-scope coverage. Generation costs average \$3.20 and approximately 10 minutes per harness, demonstrating practical feasibility for integration into continuous fuzzing workflows. During 12-hour fuzzing campaigns, our harnesses discovered 3 previously unreported bugs in commons-cli and jsoup. These discoveries occurred in methods already covered by existing OSS-Fuzz harnesses, demonstrating that automated generation achieves sufficient quality for real vulnerability discovery. In one notable case involving ANTLR4, our generated harness achieved measurable coverage on a target method where the existing OSS-Fuzz harness registered 0\% coverage throughout the entire campaign due to inability to satisfy method preconditions.


In summary, this work makes the following contributions.
\begin{itemize}
    \item A multi-agent architecture that integrates LLM reasoning with program analysis to automate harness generation for Java library APIs without requiring consumer code corpora or manual intervention.

    \item A query-driven tool interface using the Model Context Protocol that retrieves precisely scoped program information on demand, preventing context saturation while enabling exploration of large codebases.

    \item Method-targeted coverage instrumentation with agent-guided termination that interprets coverage gaps through source code analysis rather than applying fixed numerical thresholds.

    \item Empirical validation on widely deployed libraries demonstrating competitive coverage with manually written baselines, practical generation costs, and discovery of three previously unreported bugs in production code.
\end{itemize}
